{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fb7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from cleantext import clean\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "# Example command:\n",
    "# python identify_paragraphs_containing_keywords.py C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\output\\02_process_cc\\02.2_csv_20210101_20220617 C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\output\\03_identify_paragraphs_containing_keywords C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\code\\03_identify_paragraphs_containing_keywords\\reference_files\\keywords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25cd234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max number of columns and rows to display in Jupyter Notebooks\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403310cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse arguments\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Identify paragraphs containing keywords')\n",
    "    parser.add_argument('inputfolder', help=\"input folder containing the .csv files\", type=str)\n",
    "    parser.add_argument('outputfolder', help=\"output folder containing the paragraphs\", type=str)\n",
    "    parser.add_argument('keywords_filepath', help=\"filepath of the keywords.txt file\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    inputfolder = Path(args.inputfolder)\n",
    "    outputfolder = Path(args.outputfolder)\n",
    "    keywords_filepath = Path(args.keywords_filepath)\n",
    "\n",
    "print(\"Input folder:\", inputfolder)\n",
    "print(\"Output folder:\", outputfolder)\n",
    "print(\"Keywords filepath:\", keywords_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac2e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder = Path(r\"C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\output\\02_process_cc\\02.2_csv_20210101_20220617\")\n",
    "outputfolder = Path(r\"C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\output\\03_identify_paragraphs_containing_keywords\")\n",
    "keywords_filepath = Path(r\"C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\code\\03_identify_paragraphs_containing_keywords\\reference_files\\keywords.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3d362",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f02874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(s):\n",
    "    t = s.replace(\"\\\\n\", \" \")\n",
    "    t = t.replace(\"\\\\\", \"\")\n",
    "    if len(t) == 0:\n",
    "        return \"\"\n",
    "    if t[0] == '\"':\n",
    "        t = t[1:-1]\n",
    "    return clean(t, fix_unicode = True, no_line_breaks = True, lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c064a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9c77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNumbers(text):\n",
    "    digits = re.findall(r\"[(\\d.)]+\", text)\n",
    "    digits = [i for i in digits if i != \".\"]\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f32b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_n_prev_and_next(p1, p2, k, n = 5):\n",
    "    inverted_n = n * -1 ### Good for indexing purposes\n",
    "    start = p1.index(k)\n",
    "    end = start + len(k)\n",
    "    p1_start_chunk, p1_end_chunk = p1[:start], p1[end:]\n",
    "    p2_start_chunk, p2_end_chunk = p2[:start], p2[end:]\n",
    "    p1_preceding_n_words, p2_preceding_n_words = \" \".join(p1_start_chunk.split()[inverted_n:]), \" \".join(p2_start_chunk.split()[inverted_n:])\n",
    "    p1_succeding_n_words, p2_succeding_n_words = \" \".join(p1_end_chunk.split()[:n]), \" \".join(p2_end_chunk.split()[:n])\n",
    "    if (p1_preceding_n_words == p2_preceding_n_words) and (p1_succeding_n_words == p2_succeding_n_words):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06bf47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conf_call_into_paras(call):\n",
    "    paras_list = [t.replace(\"\\n\",\" \") for t in re.split(r\"\\n\\s*\\n+\", call) if len(t)>0 and not re.match(r\"^\\s*[0-9]+$\",t)]\n",
    "    return paras_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df94d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_paras_containing_keywords_from_a_conf_call(row, keywords, clean = True, lower = True):\n",
    "    # Split conference call into paragraphs.\n",
    "    # This is an imperfect split - sometimes it breaks in the middle of a sentence\n",
    "    call = str(row[\"Call\"])\n",
    "    paras_list = split_conf_call_into_paras(call)\n",
    "    found_keywords, found_in_paras = [], []\n",
    "\n",
    "    report_id = row[\"Report\"]\n",
    "    for para in paras_list:\n",
    "        for keyword in keywords:\n",
    "            # Lower case\n",
    "            if lower == True:\n",
    "                para = para.lower()\n",
    "                keyword = keyword.lower()\n",
    "            # Clean paragraph\n",
    "            if clean == True:\n",
    "                para = clean_str(para)\n",
    "            # Search for keyword\n",
    "            if keyword in para:\n",
    "                found_keywords.append(keyword)\n",
    "                found_in_paras.append(para)\n",
    "    \n",
    "    # Create df \n",
    "    # Note that found_keywords and found_in_paras are lists. \n",
    "    # report_id is an int, but it will be broadcasted to a list.\n",
    "    df = pd.DataFrame({\"keyword\": found_keywords, \"paragraph\": found_in_paras, \"report_id\": report_id})\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "771d4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_paras_containing_keywords_from_a_csv_file(csv_file):\n",
    "    df_csv_file = pd.read_csv(csv_file)\n",
    "    df_combined = pd.DataFrame()\n",
    "    for _, row_conf_call in df_csv_file.iterrows():\n",
    "        df = get_all_paras_containing_keywords_from_a_conf_call(row_conf_call, keywords, clean = False, lower = True)\n",
    "        df_combined = pd.concat([df_combined, df])\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9df38c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfilepath = Path(r\"C:\\Users\\jasonjia\\Dropbox\\Projects\\conference_call\\output\\02_process_cc\\02.2_csv_20210101_20220617\\20201229-20210101_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c13880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>report_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occ</td>\n",
       "      <td>pawan kumar goenka - mahindra &amp; mahindra limi...</td>\n",
       "      <td>71149754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occ</td>\n",
       "      <td>lawrence e. kurzius - mccormick &amp; company, inc...</td>\n",
       "      <td>71118206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occ</td>\n",
       "      <td>lawrence e. kurzius - mccormick &amp; company, inc...</td>\n",
       "      <td>71118386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interest rate</td>\n",
       "      <td>after this, we completed an $8.3 million overs...</td>\n",
       "      <td>71118254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>occ</td>\n",
       "      <td>following the presentation of these proposals,...</td>\n",
       "      <td>71118259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interest rate</td>\n",
       "      <td>in addition, in recent years, we're also goin...</td>\n",
       "      <td>71118480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>improve and achieve a return on capital which...</td>\n",
       "      <td>71118480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>unidentified company representative [interpret...</td>\n",
       "      <td>71118480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>interest rate</td>\n",
       "      <td>so apart from getting the resolution done with...</td>\n",
       "      <td>71117411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>at its core, this is a favorable recapitalizat...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>second, jp morgan broker-dealer holdings, or j...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>the end result is that through this restructur...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>brian alexitch - greenwich investment manageme...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>peter andrew reed - great elm group, inc. - ce...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cost of capital</td>\n",
       "      <td>so not only we've lowered the cost of capital,...</td>\n",
       "      <td>71114841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           keyword                                          paragraph  \\\n",
       "0              occ   pawan kumar goenka - mahindra & mahindra limi...   \n",
       "0              occ  lawrence e. kurzius - mccormick & company, inc...   \n",
       "0              occ  lawrence e. kurzius - mccormick & company, inc...   \n",
       "0    interest rate  after this, we completed an $8.3 million overs...   \n",
       "0              occ  following the presentation of these proposals,...   \n",
       "0    interest rate   in addition, in recent years, we're also goin...   \n",
       "1  cost of capital   improve and achieve a return on capital which...   \n",
       "2  cost of capital  unidentified company representative [interpret...   \n",
       "0    interest rate  so apart from getting the resolution done with...   \n",
       "0  cost of capital  at its core, this is a favorable recapitalizat...   \n",
       "1  cost of capital  second, jp morgan broker-dealer holdings, or j...   \n",
       "2  cost of capital  the end result is that through this restructur...   \n",
       "3  cost of capital  brian alexitch - greenwich investment manageme...   \n",
       "4  cost of capital  peter andrew reed - great elm group, inc. - ce...   \n",
       "5  cost of capital  so not only we've lowered the cost of capital,...   \n",
       "\n",
       "   report_id  \n",
       "0   71149754  \n",
       "0   71118206  \n",
       "0   71118386  \n",
       "0   71118254  \n",
       "0   71118259  \n",
       "0   71118480  \n",
       "1   71118480  \n",
       "2   71118480  \n",
       "0   71117411  \n",
       "0   71114841  \n",
       "1   71114841  \n",
       "2   71114841  \n",
       "3   71114841  \n",
       "4   71114841  \n",
       "5   71114841  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_file = pd.read_csv(csv_file)\n",
    "df_combined = []\n",
    "get_all_paras_containing_keywords_from_a_conf_call(df_csv_file.iloc[0], keywords, clean = False, lower = True)\n",
    "get_all_paras_containing_keywords_from_a_csv_file(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d33e1b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jasonjia/Dropbox/Projects/conference_call/output/02_process_cc/02.2_csv_20210101_20220617/20201229-20210101_1.csv')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b72fd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d0a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop\n",
    "keywords = pd.read_csv(keywords_filepath, sep = \"\\t\", header = None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520e58ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Para'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Para'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m unclean_data \u001b[38;5;241m=\u001b[39m unclean_data\u001b[38;5;241m.\u001b[39mmerge(df, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m      5\u001b[0m unclean_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m file\n\u001b[1;32m----> 6\u001b[0m unclean_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHasNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43munclean_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPara\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(has_numbers)\n\u001b[0;32m      7\u001b[0m outputfilepath \u001b[38;5;241m=\u001b[39m Path(outputfolder \u001b[38;5;241m/\u001b[39m file)\n\u001b[0;32m      8\u001b[0m unclean_data\u001b[38;5;241m.\u001b[39mto_parquet(outputfilepath, compression \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Para'"
     ]
    }
   ],
   "source": [
    "for csv_file in inputfolder.iterdir():    \n",
    "    df_combined = get_all_paragraphs_containing_keywords_from_a_csv_file(csv_file)\n",
    "    unclean_data = pd.concat(df_combined).reset_index(drop = True)\n",
    "    unclean_data = unclean_data.merge(df, on = \"Report\", how = \"left\") \n",
    "    unclean_data[\"File\"] = file\n",
    "    unclean_data[\"HasNumber\"] = unclean_data[\"Para\"].apply(has_numbers)\n",
    "    outputfilepath = Path(outputfolder / file)\n",
    "    unclean_data.to_parquet(outputfilepath, compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15a3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
